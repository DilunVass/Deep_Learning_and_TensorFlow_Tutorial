{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NLP Fundamentals in TensorFlow\n",
    "\n",
    "Natural Language Processing (NLP) is a field in machine learning with the ability of a computer to understand, interpret, and generate human language. NLP is a subset of artificial intelligence and is widely used in applications like language translation, chatbots, sentiment analysis, speech recognition, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chech for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Oct 16 11:29:59 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.90                 Driver Version: 565.90         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| 26%   40C    P8             14W /  120W |     562MiB /   4096MiB |     10%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2216    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A      2436    C+G   ...on\\129.0.2792.89\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     10152    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A     11452    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     11716    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     14804    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     15276    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     16112    C+G   ...US\\ArmouryDevice\\asus_framework.exe      N/A      |\n",
      "|    0   N/A  N/A     16124    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     16216    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     16748    C+G   ...tionsPlus\\logioptionsplus_agent.exe      N/A      |\n",
      "|    0   N/A  N/A     18108    C+G   ...on\\129.0.2792.89\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     18320    C+G   ...mpt_builder\\LogiAiPromptBuilder.exe      N/A      |\n",
      "|    0   N/A  N/A     19620    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     19652    C+G   ....5131.0_x64__8j3eq9eme6ctt\\IGCC.exe      N/A      |\n",
      "|    0   N/A  N/A     20256    C+G   ...cal\\Microsoft\\OneDrive\\OneDrive.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We create a bunch of helpful functions throughout the course.\n",
    "### Storing them here so they're easily accessible.\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create a function to import an image and resize it to be able to be used with our model\n",
    "def load_and_prep_image(filename, img_shape=224, scale=True):\n",
    "  \"\"\"\n",
    "  Reads in an image from filename, turns it into a tensor and reshapes into\n",
    "  (224, 224, 3).\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  filename (str): string filename of target image\n",
    "  img_shape (int): size to resize target image to, default 224\n",
    "  scale (bool): whether to scale pixel values to range(0, 1), default True\n",
    "  \"\"\"\n",
    "  # Read in the image\n",
    "  img = tf.io.read_file(filename)\n",
    "  # Decode it into a tensor\n",
    "  img = tf.image.decode_jpeg(img)\n",
    "  # Resize the image\n",
    "  img = tf.image.resize(img, [img_shape, img_shape])\n",
    "  if scale:\n",
    "    # Rescale the image (get all values between 0 and 1)\n",
    "    return img/255.\n",
    "  else:\n",
    "    return img\n",
    "\n",
    "# Note: The following confusion matrix code is a remix of Scikit-Learn's \n",
    "# plot_confusion_matrix function - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Our function needs a different name to sklearn's plot_confusion_matrix\n",
    "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False): \n",
    "  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
    "\n",
    "  If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
    "  will be used.\n",
    "\n",
    "  Args:\n",
    "    y_true: Array of truth labels (must be same shape as y_pred).\n",
    "    y_pred: Array of predicted labels (must be same shape as y_true).\n",
    "    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
    "    figsize: Size of output figure (default=(10, 10)).\n",
    "    text_size: Size of output figure text (default=15).\n",
    "    norm: normalize values or not (default=False).\n",
    "    savefig: save confusion matrix to file (default=False).\n",
    "  \n",
    "  Returns:\n",
    "    A labelled confusion matrix plot comparing y_true and y_pred.\n",
    "\n",
    "  Example usage:\n",
    "    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
    "                          y_pred=y_preds, # predicted labels\n",
    "                          classes=class_names, # array of class label names\n",
    "                          figsize=(15, 15),\n",
    "                          text_size=10)\n",
    "  \"\"\"  \n",
    "  # Create the confustion matrix\n",
    "  cm = confusion_matrix(y_true, y_pred)\n",
    "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
    "  n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
    "\n",
    "  # Plot the figure and make it pretty\n",
    "  fig, ax = plt.subplots(figsize=figsize)\n",
    "  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
    "  fig.colorbar(cax)\n",
    "\n",
    "  # Are there a list of classes?\n",
    "  if classes:\n",
    "    labels = classes\n",
    "  else:\n",
    "    labels = np.arange(cm.shape[0])\n",
    "  \n",
    "  # Label the axes\n",
    "  ax.set(title=\"Confusion Matrix\",\n",
    "         xlabel=\"Predicted label\",\n",
    "         ylabel=\"True label\",\n",
    "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
    "         yticks=np.arange(n_classes), \n",
    "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
    "         yticklabels=labels)\n",
    "  \n",
    "  # Make x-axis labels appear on bottom\n",
    "  ax.xaxis.set_label_position(\"bottom\")\n",
    "  ax.xaxis.tick_bottom()\n",
    "\n",
    "  # Set the threshold for different colors\n",
    "  threshold = (cm.max() + cm.min()) / 2.\n",
    "\n",
    "  # Plot the text on each cell\n",
    "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    if norm:\n",
    "      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
    "              horizontalalignment=\"center\",\n",
    "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "              size=text_size)\n",
    "    else:\n",
    "      plt.text(j, i, f\"{cm[i, j]}\",\n",
    "              horizontalalignment=\"center\",\n",
    "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "              size=text_size)\n",
    "\n",
    "  # Save the figure to the current working directory\n",
    "  if savefig:\n",
    "    fig.savefig(\"confusion_matrix.png\")\n",
    "  \n",
    "# Make a function to predict on images and plot them (works with multi-class)\n",
    "def pred_and_plot(model, filename, class_names):\n",
    "  \"\"\"\n",
    "  Imports an image located at filename, makes a prediction on it with\n",
    "  a trained model and plots the image with the predicted class as the title.\n",
    "  \"\"\"\n",
    "  # Import the target image and preprocess it\n",
    "  img = load_and_prep_image(filename)\n",
    "\n",
    "  # Make a prediction\n",
    "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
    "\n",
    "  # Get the predicted class\n",
    "  if len(pred[0]) > 1: # check for multi-class\n",
    "    pred_class = class_names[pred.argmax()] # if more than one output, take the max\n",
    "  else:\n",
    "    pred_class = class_names[int(tf.round(pred)[0][0])] # if only one output, round\n",
    "\n",
    "  # Plot the image and predicted class\n",
    "  plt.imshow(img)\n",
    "  plt.title(f\"Prediction: {pred_class}\")\n",
    "  plt.axis(False);\n",
    "  \n",
    "import datetime\n",
    "\n",
    "def create_tensorboard_callback(dir_name, experiment_name):\n",
    "  \"\"\"\n",
    "  Creates a TensorBoard callback instand to store log files.\n",
    "\n",
    "  Stores log files with the filepath:\n",
    "    \"dir_name/experiment_name/current_datetime/\"\n",
    "\n",
    "  Args:\n",
    "    dir_name: target directory to store TensorBoard log files\n",
    "    experiment_name: name of experiment directory (e.g. efficientnet_model_1)\n",
    "  \"\"\"\n",
    "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "      log_dir=log_dir\n",
    "  )\n",
    "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
    "  return tensorboard_callback\n",
    "\n",
    "# Plot the validation and training data separately\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_curves(history):\n",
    "  \"\"\"\n",
    "  Returns separate loss curves for training and validation metrics.\n",
    "\n",
    "  Args:\n",
    "    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)\n",
    "  \"\"\" \n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  accuracy = history.history['accuracy']\n",
    "  val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "  epochs = range(len(history.history['loss']))\n",
    "\n",
    "  # Plot loss\n",
    "  plt.plot(epochs, loss, label='training_loss')\n",
    "  plt.plot(epochs, val_loss, label='val_loss')\n",
    "  plt.title('Loss')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend()\n",
    "\n",
    "  # Plot accuracy\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
    "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
    "  plt.title('Accuracy')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend();\n",
    "\n",
    "def compare_historys(original_history, new_history, initial_epochs=5):\n",
    "    \"\"\"\n",
    "    Compares two TensorFlow model History objects.\n",
    "    \n",
    "    Args:\n",
    "      original_history: History object from original model (before new_history)\n",
    "      new_history: History object from continued model training (after original_history)\n",
    "      initial_epochs: Number of epochs in original_history (new_history plot starts from here) \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get original history measurements\n",
    "    acc = original_history.history[\"accuracy\"]\n",
    "    loss = original_history.history[\"loss\"]\n",
    "\n",
    "    val_acc = original_history.history[\"val_accuracy\"]\n",
    "    val_loss = original_history.history[\"val_loss\"]\n",
    "\n",
    "    # Combine original history with new history\n",
    "    total_acc = acc + new_history.history[\"accuracy\"]\n",
    "    total_loss = loss + new_history.history[\"loss\"]\n",
    "\n",
    "    total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n",
    "    total_val_loss = val_loss + new_history.history[\"val_loss\"]\n",
    "\n",
    "    # Make plots\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(total_acc, label='Training Accuracy')\n",
    "    plt.plot(total_val_acc, label='Validation Accuracy')\n",
    "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
    "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(total_loss, label='Training Loss')\n",
    "    plt.plot(total_val_loss, label='Validation Loss')\n",
    "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
    "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "  \n",
    "# Create function to unzip a zipfile into current working directory \n",
    "# (since we're going to be downloading and unzipping a few files)\n",
    "import zipfile\n",
    "\n",
    "def unzip_data(filename):\n",
    "  \"\"\"\n",
    "  Unzips filename into the current working directory.\n",
    "\n",
    "  Args:\n",
    "    filename (str): a filepath to a target zip folder to be unzipped.\n",
    "  \"\"\"\n",
    "  zip_ref = zipfile.ZipFile(filename, \"r\")\n",
    "  zip_ref.extractall()\n",
    "  zip_ref.close()\n",
    "\n",
    "# Walk through an image classification directory and find out how many files (images)\n",
    "# are in each subdirectory.\n",
    "import os\n",
    "\n",
    "def walk_through_dir(dir_path):\n",
    "  \"\"\"\n",
    "  Walks through dir_path returning its contents.\n",
    "\n",
    "  Args:\n",
    "    dir_path (str): target directory\n",
    "  \n",
    "  Returns:\n",
    "    A print out of:\n",
    "      number of subdiretories in dir_path\n",
    "      number of images (files) in each subdirectory\n",
    "      name of each subdirectory\n",
    "  \"\"\"\n",
    "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
    "    \n",
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "\n",
    "  Args:\n",
    "      y_true: true labels in the form of a 1D array\n",
    "      y_pred: predicted labels in the form of a 1D array\n",
    "\n",
    "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
    "  \"\"\"\n",
    "  # Calculate model accuracy\n",
    "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "  # Calculate model precision, recall and f1 score using \"weighted average\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "  model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "  return model_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"data/train/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   id keyword location                                               text  \\\n",
       " 0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       " 1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       " 2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       " 3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       " 4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       " \n",
       "    target  \n",
       " 0       1  \n",
       " 1       1  \n",
       " 2       1  \n",
       " 3       1  \n",
       " 4       1  ,\n",
       "    id keyword location                                               text\n",
       " 0   0     NaN      NaN                 Just happened a terrible car crash\n",
       " 1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       " 2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       " 3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       " 4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(), test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Forest fire near La Ronge Sask. Canada'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"text\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle the training dataframe\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data frame looks like\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4342\n",
       "1    3271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examples of each class\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3263)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of samples\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "A new tropical cyclone is forming near Guam.\n",
      "\n",
      "Once it is formed it will be called 'Molave'.\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Ancient Mayan Tablet found via http://t.co/LmUMzkLtln http://t.co/yebxxAryBF http://t.co/SRRUqfffr6 http://t.co/CadzxAgMSI\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "3. excessive engine failure rate significant maintenance constantly emerging structural defects. Phew that's a lot I say.\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "This is the first year the Forest Service spent more than half its annual budget on fighting fires. #climatechange http://t.co/D62zfZy0Mi\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "Imagine a room with walls that are lava lamps.\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualize the random training samples\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random_index = random.randint(0, len(train_df)-5) # create random indexes not exceeding total number of samples\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "    _, text, target = row\n",
    "    print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
    "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
    "                                                                            test_size=0.1,\n",
    "                                                                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the lengths\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first 10 samples\n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting text into numbers\n",
    "\n",
    "First step in working with text data is to convert them into numbers. There are few ways to do this:\n",
    "* Tokenization - Direct mapping of token (a token could be a word or a character) to number.\n",
    "* Embedding - Create a matrix of feature vector for each token (word) and use those vectors as features for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Vectorization (Tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0], dtype=int64))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:5], train_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "#from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "# Use the default TextVectorization variables\n",
    "text_vectorization = TextVectorization(max_tokens=10000, # Set max_tokens to a specific integer value\n",
    "                                       standardize=\"lower_and_strip_punctuation\",\n",
    "                                       split=\"whitespace\",\n",
    "                                       ngrams=None, # Create groups of n-words?\n",
    "                                       output_mode=\"int\", # How to map tokens to numbers\n",
    "                                       output_sequence_length=None, # How long do you want your sequences to be\n",
    "                                       pad_to_max_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the average number of tokens in the training data\n",
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup text vectorization variables\n",
    "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
    "max_length = 15 # max length of the sequence\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 264,    3,  232,    4,    2, 1585,    6,   50,  913,    0,    0,\n",
       "           0,    0,    0,    0]], dtype=int64)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample sentence and tokenize it\n",
    "sample_sentence = \"There's a flood in the streets of New York\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "ISIS claims responsibility for Saudi mosque suicide bombing http://t.co/Wpilp4mymf http://t.co/8NHD9iDaJs      \n",
      "\n",
      "Vectorized version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 543, 1091, 2745,   10,  312,  393,   87,  156,    1,    1,    0,\n",
       "           0,    0,    0,    0]], dtype=int64)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a random sentence from the training dataset and tokenize it\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nVectorized version:\")\n",
    "text_vectorizer([random_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 10000\n",
      "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
      "Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary() # get all of the unique words in our training data\n",
    "top_5_words = words_in_vocab[:5] # get the most common words\n",
    "bottom_5_words = words_in_vocab[-5:] # get the least common words\n",
    "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
    "print(f\"Top 5 most common words: {top_5_words}\") # most common words\n",
    "print(f\"Bottom 5 least common words: {bottom_5_words}\") # least common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length of the vocabulary\n",
    "len(words_in_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Embedding using an Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x28020f6c9a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = tf.keras.layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
    "                                      output_dim=128, # set size of embedding vector\n",
    "                                      embeddings_initializer=\"uniform\", # default initilization\n",
    "                                      input_length=max_length) # how long is each input\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "The worst  voice I can ever hear is the 'Nikki your in trouble' voice from my mom      \n",
      "\n",
      "Embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[ 0.03971504, -0.0495409 ,  0.04346852, ..., -0.00804331,\n",
       "         -0.01827847, -0.01137704],\n",
       "        [-0.04486055,  0.03499627, -0.00536363, ..., -0.04541416,\n",
       "          0.01321376, -0.04569539],\n",
       "        [-0.02556449,  0.0278378 ,  0.00967627, ..., -0.00189561,\n",
       "         -0.00862938, -0.02787207],\n",
       "        ...,\n",
       "        [ 0.02560495, -0.04586787, -0.01867702, ..., -0.0204574 ,\n",
       "          0.03844272,  0.0061137 ],\n",
       "        [-0.02556449,  0.0278378 ,  0.00967627, ..., -0.00189561,\n",
       "         -0.00862938, -0.02787207],\n",
       "        [-0.04513955,  0.01091326,  0.04228255, ..., -0.02248303,\n",
       "         -0.04155282, -0.01775597]]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence from the training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nEmbedded version:\")\n",
    "\n",
    "# Embed the random sentence (turn it into dense vectors of fixed size)\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       "array([ 0.03971504, -0.0495409 ,  0.04346852, -0.00212915, -0.01200577,\n",
       "       -0.04859258, -0.04638335,  0.04696903,  0.02986819,  0.02672087,\n",
       "       -0.04542642, -0.0350984 ,  0.00212008, -0.02408137, -0.02694554,\n",
       "       -0.0294016 ,  0.02693609,  0.01532818,  0.00445766, -0.00619947,\n",
       "       -0.03783375,  0.04826387,  0.02276354, -0.03980042,  0.01788456,\n",
       "        0.04706727, -0.00481606,  0.02491068, -0.03452582,  0.04699022,\n",
       "        0.0058786 , -0.01384375,  0.02607739, -0.01061579, -0.02405105,\n",
       "       -0.04237769, -0.03558876,  0.03196484, -0.02636085,  0.03570018,\n",
       "        0.00504016,  0.01716173, -0.04234595,  0.00647129, -0.00930806,\n",
       "       -0.04570727,  0.04662803, -0.02241135,  0.01043181, -0.03249275,\n",
       "       -0.04481908, -0.01704096, -0.04156995, -0.03595246,  0.04589612,\n",
       "        0.0416267 , -0.03989383, -0.00762738,  0.01421714, -0.04481889,\n",
       "       -0.03525258,  0.03175077, -0.01248563,  0.03360114,  0.02283814,\n",
       "        0.04673339, -0.03118819, -0.02124999,  0.045299  , -0.02877388,\n",
       "        0.03128413,  0.0296904 ,  0.0480223 ,  0.04533689,  0.04359413,\n",
       "       -0.01509776, -0.0264882 ,  0.03785871, -0.04451093,  0.01630939,\n",
       "       -0.01808696, -0.03654717, -0.01951855, -0.00385662, -0.01561189,\n",
       "        0.04674761,  0.04188297, -0.00561793, -0.04947754, -0.00089059,\n",
       "       -0.03395756,  0.04097507, -0.03224788,  0.04119838, -0.04848288,\n",
       "       -0.04249561,  0.04956651,  0.00450027,  0.00888987,  0.03736005,\n",
       "       -0.03563295,  0.02896065, -0.03234588,  0.02013731,  0.04761484,\n",
       "        0.03289567, -0.03659204,  0.02236711,  0.01479235,  0.00368489,\n",
       "        0.02767697, -0.03443793, -0.02615857, -0.02723189, -0.00202139,\n",
       "       -0.04079285, -0.00141182, -0.01491209, -0.04382109,  0.02845621,\n",
       "       -0.01827537, -0.00092278,  0.01221988, -0.02731358, -0.03309025,\n",
       "       -0.00804331, -0.01827847, -0.01137704], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_embed[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling a text dataset (setting up modelling experiments)\n",
    "\n",
    "* Model 0: Naive Bayes (baseline)\n",
    "* Model 1: Feed-forward neural network (dense model)\n",
    "* Model 2: LSTM model\n",
    "* Model 3: GRU model\n",
    "* Model 4: Bidirectional-LSTM model\n",
    "* Model 5: 1D Convolutional Neural Network\n",
    "* Model 6: TensorFlow Hub Pretrained Feature Extractor\n",
    "* Model 7: Same as model 6 with 10% of the training data\n",
    "\n",
    "Steps for each model:\n",
    "1. Construct the model\n",
    "2. Train the model\n",
    "3. Make predictions\n",
    "4. Track the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 0: Naive Bayes (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create Tokenization and Modelling Pipeline\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
    "    (\"clf\", MultinomialNB()) # model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model accuracy: 79.27%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the baseline model\n",
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Baseline model accuracy: {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an evaluation function for model experiments\n",
    "\n",
    "Modelling experiments are typically evaluated using:\n",
    "* Accuracy - the higher the better\n",
    "* Precision - the higher the better\n",
    "* Recall - the higher the better\n",
    "* F1-score - the higher the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "\n",
    "    Args:\n",
    "        y_true: true labels in the form of a 1D array\n",
    "        y_pred: predicted labels in the form of a 1D array\n",
    "\n",
    "    Returns a dictionary of accuracy, precision, recall, f1-score.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate model accuracy\n",
    "    model_accuracy = accuracy_score(y_true, y_pred) * 100 # get accuracy score in percentage\n",
    "    # Calculate model precision, recall and f1 score using \"weighted average\"\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    # Create a dictionary of results\n",
    "    model_results = {\"accuracy\": model_accuracy,\n",
    "                     \"precision\": model_precision,\n",
    "                     \"recall\": model_recall,\n",
    "                     \"f1 score\": model_f1}\n",
    "    \n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1 score': 0.7862189758049549}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels,\n",
    "                                     y_pred=baseline_preds)\n",
    "\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Feed-forward neural network (dense model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to save TensorBoard logs\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "       'Imagine getting flattened by Kurt Zouma',\n",
       "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model using the Sequential API\n",
    "from tensorflow.keras import layers\n",
    "input = layers.Input(shape=(1,), dtype=tf.string) # inputs are 1-dimensional strings\n",
    "x = text_vectorizer(input) # turn the input text into numbers\n",
    "x = embedding(x) # create an embedding of the numberized inputs\n",
    "x = layers.GlobalAveragePooling1D()(x) # condense the feature vector for each token to one vector\n",
    "\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer, want binary output so use sigmoid activation function\n",
    "model_1 = tf.keras.Model(input, output, name=\"model_1_dense\") # construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_1_dense/20241016-113001\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 5s 17ms/step - loss: 0.6142 - accuracy: 0.6914 - val_loss: 0.5414 - val_accuracy: 0.7454\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.4434 - accuracy: 0.8177 - val_loss: 0.4712 - val_accuracy: 0.7861\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.3478 - accuracy: 0.8613 - val_loss: 0.4617 - val_accuracy: 0.7874\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 16ms/step - loss: 0.2854 - accuracy: 0.8885 - val_loss: 0.4631 - val_accuracy: 0.7887\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.2377 - accuracy: 0.9115 - val_loss: 0.4888 - val_accuracy: 0.7900\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model_1.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model_1_history = model_1.fit(train_sentences, train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                                    experiment_name=\"model_1_dense\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48875612020492554, 0.7900262475013733]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model_1.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.28891802],\n",
       "       [0.8570126 ],\n",
       "       [0.9975726 ],\n",
       "       [0.08191413],\n",
       "       [0.10381918],\n",
       "       [0.9258567 ],\n",
       "       [0.88871014],\n",
       "       [0.99258786],\n",
       "       [0.96224165],\n",
       "       [0.20009117]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model_1 pred probs from probabilities to prediction labels\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
    "model_1_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.00262467191601,\n",
       " 'precision': 0.7986440245389494,\n",
       " 'recall': 0.7900262467191601,\n",
       " 'f1 score': 0.7859832179841351}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model_1 with evaluate function\n",
    "model_1_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_1_preds)\n",
    "\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1 score': 0.7862189758049549}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing learned embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the vocabulary from the text vectorization layer\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "\n",
    "len(words_in_vocab), words_in_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 128)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the weight matrix of the embedding layer\n",
    "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
    "embed_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "# Code to save trained embeddings to file - we got this from here: https://www.tensorflow.org/tutorials/text/word_embeddings#retrieve_the_trained_word_embeddings_and_save_them_to_disk\n",
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(words_in_vocab):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  vec = embed_weights[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: LSTM model\n",
    "\n",
    "* LSTM (Long Short Term Memory) - one of the most popular LSTM cells. LSTM cells have the ability to \"remember\" things which are important in natural language processing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After embedding: (None, 15, 128)\n",
      "After LSTM cellL (None, 64)\n"
     ]
    }
   ],
   "source": [
    "# Create LSTM model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "print(f\"After embedding: {x.shape}\")\n",
    "\n",
    "\n",
    "x = layers.LSTM(64, activation=\"tanh\")(x)\n",
    "print(f\"After LSTM cellL {x.shape}\")\n",
    "\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_2_LSTM/20241016-113024\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 11s 29ms/step - loss: 0.2221 - accuracy: 0.9212 - val_loss: 0.5043 - val_accuracy: 0.7835\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 5s 25ms/step - loss: 0.1554 - accuracy: 0.9409 - val_loss: 0.6110 - val_accuracy: 0.7808\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.1301 - accuracy: 0.9492 - val_loss: 0.6243 - val_accuracy: 0.7874\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.1064 - accuracy: 0.9607 - val_loss: 0.6943 - val_accuracy: 0.7835\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0868 - accuracy: 0.9650 - val_loss: 0.7425 - val_accuracy: 0.7703\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model_2.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model_2_history = model_2.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                                     experiment_name=\"model_2_LSTM\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((762, 1),\n",
       " array([[0.02489586],\n",
       "        [0.8026455 ],\n",
       "        [0.9992683 ],\n",
       "        [0.10699368],\n",
       "        [0.00124199],\n",
       "        [0.96644694],\n",
       "        [0.40446305],\n",
       "        [0.99943876],\n",
       "        [0.99937904],\n",
       "        [0.49032447]], dtype=float32))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs.shape, model_2_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 0., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round out pred probs and reduce to 1-dim array\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.03412073490814,\n",
       " 'precision': 0.7718252603398367,\n",
       " 'recall': 0.7703412073490814,\n",
       " 'f1 score': 0.7683227325217538}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate LSTM model results\n",
    "model_2_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_2_preds)\n",
    "\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: GRU mdoel\n",
    "\n",
    "* GRU (Gated Recurrent Unit) - a variation of the LSTM cell but with less parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a RNN using the GRU cell\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "# x = layers.GRU(64, activation=\"tanh\", return_sequences=True)(x) # return_sequences=True is required for stacking recurrent cells\n",
    "# print(x.shape)\n",
    "x = layers.GRU(64, activation=\"tanh\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_2_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_GRU\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,317,313\n",
      "Trainable params: 1,317,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model Summary\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_3_GRU/20241016-113055\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 9s 28ms/step - loss: 0.1502 - accuracy: 0.9426 - val_loss: 0.8794 - val_accuracy: 0.7730\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0812 - accuracy: 0.9696 - val_loss: 0.9272 - val_accuracy: 0.7743\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0726 - accuracy: 0.9731 - val_loss: 0.9347 - val_accuracy: 0.7782\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0679 - accuracy: 0.9733 - val_loss: 0.9727 - val_accuracy: 0.7690\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0583 - accuracy: 0.9753 - val_loss: 1.0506 - val_accuracy: 0.7782\n"
     ]
    }
   ],
   "source": [
    "# Compile the model_3\n",
    "model_3.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model_3\n",
    "model_3_history = model_3.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                                     experiment_name=\"model_3_GRU\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[2.2117095e-03],\n",
       "        [6.2240177e-01],\n",
       "        [9.9990207e-01],\n",
       "        [2.1316718e-02],\n",
       "        [2.3604531e-04],\n",
       "        [9.9951530e-01],\n",
       "        [7.0896173e-01],\n",
       "        [9.9996144e-01],\n",
       "        [9.9990803e-01],\n",
       "        [4.8417652e-01]], dtype=float32),\n",
       " (762, 1))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with model_3\n",
    "model_3_pred_probs = model_3.predict(val_sentences)\n",
    "model_3_pred_probs[:10], model_3_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model_3 preds probs into labels\n",
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
    "model_3_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.82152230971128,\n",
       " 'precision': 0.7810722984564322,\n",
       " 'recall': 0.7782152230971129,\n",
       " 'f1 score': 0.7757459581978545}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_3 results\n",
    "model_3_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_3_preds)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: Bidirectional-LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model with bidrrectional RNN in TensorFlow\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidirectional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_bidirectional\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,378,945\n",
      "Trainable params: 1,378,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20241016-113126\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 12s 32ms/step - loss: 0.1078 - accuracy: 0.9670 - val_loss: 0.9482 - val_accuracy: 0.7717\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 6s 27ms/step - loss: 0.0559 - accuracy: 0.9784 - val_loss: 1.2313 - val_accuracy: 0.7769\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 6s 27ms/step - loss: 0.0463 - accuracy: 0.9791 - val_loss: 1.3486 - val_accuracy: 0.7769\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 6s 28ms/step - loss: 0.0413 - accuracy: 0.9809 - val_loss: 1.3369 - val_accuracy: 0.7677\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 6s 27ms/step - loss: 0.0446 - accuracy: 0.9801 - val_loss: 1.4636 - val_accuracy: 0.7638\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model_4.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model\n",
    "model_4_history = model_4.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                                     experiment_name=\"model_4_bidirectional\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[3.5377888e-03],\n",
       "        [7.6891071e-01],\n",
       "        [9.9996978e-01],\n",
       "        [7.3083229e-02],\n",
       "        [2.5641304e-05],\n",
       "        [9.9895060e-01],\n",
       "        [2.5077069e-01],\n",
       "        [9.9998927e-01],\n",
       "        [9.9997312e-01],\n",
       "        [9.9577624e-01]], dtype=float32),\n",
       " (762, 1))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with model_4\n",
    "model_4_pred_probs = model_4.predict(val_sentences)\n",
    "model_4_pred_probs[:10], model_4_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 0., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert pred probs to labels\n",
    "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
    "model_4_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.37795275590551,\n",
       " 'precision': 0.7638046232237288,\n",
       " 'recall': 0.7637795275590551,\n",
       " 'f1 score': 0.7625889751874003}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_4 results\n",
    "model_4_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: 1D Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding output shape: (1, 15, 128)\n",
      "Conv1D output shape: (1, 11, 32)\n",
      "Max pool output shape: (1, 32)\n"
     ]
    }
   ],
   "source": [
    "# Test to understand what things look like in Conv1D layer\n",
    "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sentence into embedding\n",
    "conv_1d_layer = layers.Conv1D(filters=32,\n",
    "                              kernel_size=5, # setting this to 5 means it'll look at 5 words at a time, 3 would mean 3 words at a time\n",
    "                              activation=\"relu\")\n",
    "conv_1d_output = conv_1d_layer(embedding_test)\n",
    "max_pool = layers.GlobalMaxPool1D()\n",
    "max_pool_output = max_pool(conv_1d_output)\n",
    "print(f\"Embedding output shape: {embedding_test.shape}\")\n",
    "print(f\"Conv1D output shape: {conv_1d_output.shape}\")\n",
    "print(f\"Max pool output shape: {max_pool_output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding output: [[[ 0.02651977  0.02018269 -0.07743363 ...  0.00445093 -0.02150951\n",
      "   -0.07523359]\n",
      "  [ 0.04031622 -0.02113115  0.01728627 ...  0.0515223  -0.03638303\n",
      "   -0.04478361]\n",
      "  [-0.0325738   0.0153787   0.00937999 ...  0.00719405 -0.06436022\n",
      "   -0.08531646]\n",
      "  ...\n",
      "  [ 0.00610882  0.02215364 -0.0353632  ... -0.00304744  0.00132309\n",
      "   -0.01143377]\n",
      "  [ 0.00610882  0.02215364 -0.0353632  ... -0.00304744  0.00132309\n",
      "   -0.01143377]\n",
      "  [ 0.00610882  0.02215364 -0.0353632  ... -0.00304744  0.00132309\n",
      "   -0.01143377]]]\n",
      "Conv1D output: [[[0.01928791 0.05547646 0.         0.02349567 0.02549222 0.\n",
      "   0.07075743 0.03232131 0.         0.         0.         0.07566359\n",
      "   0.         0.         0.01074565 0.03142922 0.         0.\n",
      "   0.         0.         0.02293313 0.         0.         0.01407429\n",
      "   0.02405596 0.11169372 0.00364238 0.01068487 0.00551267 0.00028594\n",
      "   0.01071792 0.        ]\n",
      "  [0.02468107 0.01110977 0.         0.04562294 0.069979   0.\n",
      "   0.         0.0042907  0.         0.         0.         0.\n",
      "   0.02025691 0.00958861 0.         0.07701567 0.         0.\n",
      "   0.         0.03944401 0.09731936 0.0394225  0.06145326 0.02925109\n",
      "   0.         0.01135956 0.         0.         0.         0.07034916\n",
      "   0.         0.        ]\n",
      "  [0.05571068 0.         0.         0.03072588 0.10473784 0.\n",
      "   0.02435631 0.         0.         0.         0.         0.02418877\n",
      "   0.         0.         0.         0.01153569 0.04481992 0.\n",
      "   0.         0.03882976 0.04199749 0.         0.         0.01644208\n",
      "   0.         0.         0.         0.04142802 0.01755589 0.0435136\n",
      "   0.         0.        ]\n",
      "  [0.03424673 0.         0.0684483  0.00281936 0.02578228 0.\n",
      "   0.01004824 0.         0.02580475 0.         0.         0.\n",
      "   0.         0.         0.00059778 0.         0.03352107 0.\n",
      "   0.         0.04659469 0.01940557 0.         0.         0.0005413\n",
      "   0.         0.         0.         0.01622918 0.0526284  0.04420425\n",
      "   0.03389195 0.03251328]\n",
      "  [0.07870724 0.         0.04277882 0.00343007 0.00296845 0.\n",
      "   0.03762269 0.01922255 0.         0.         0.         0.00587523\n",
      "   0.         0.01473156 0.00052313 0.03906548 0.0039789  0.\n",
      "   0.         0.         0.01989469 0.         0.         0.01491618\n",
      "   0.         0.         0.04307384 0.         0.00826754 0.0453309\n",
      "   0.04061187 0.        ]\n",
      "  [0.06339604 0.01759914 0.02181288 0.         0.03351411 0.\n",
      "   0.00526312 0.00964189 0.         0.00087711 0.         0.00306214\n",
      "   0.         0.         0.00378612 0.03538098 0.         0.\n",
      "   0.         0.         0.         0.         0.00350289 0.0315371\n",
      "   0.         0.         0.         0.         0.010626   0.07200741\n",
      "   0.03575949 0.        ]\n",
      "  [0.06339604 0.01759914 0.02181288 0.         0.03351411 0.\n",
      "   0.00526312 0.00964189 0.         0.00087711 0.         0.00306214\n",
      "   0.         0.         0.00378612 0.03538098 0.         0.\n",
      "   0.         0.         0.         0.         0.00350289 0.0315371\n",
      "   0.         0.         0.         0.         0.010626   0.07200741\n",
      "   0.03575949 0.        ]\n",
      "  [0.06339604 0.01759914 0.02181288 0.         0.03351411 0.\n",
      "   0.00526312 0.00964189 0.         0.00087711 0.         0.00306214\n",
      "   0.         0.         0.00378612 0.03538098 0.         0.\n",
      "   0.         0.         0.         0.         0.00350289 0.0315371\n",
      "   0.         0.         0.         0.         0.010626   0.07200741\n",
      "   0.03575949 0.        ]\n",
      "  [0.06339604 0.01759914 0.02181288 0.         0.03351411 0.\n",
      "   0.00526312 0.00964189 0.         0.00087711 0.         0.00306214\n",
      "   0.         0.         0.00378612 0.03538098 0.         0.\n",
      "   0.         0.         0.         0.         0.00350289 0.0315371\n",
      "   0.         0.         0.         0.         0.010626   0.07200741\n",
      "   0.03575949 0.        ]\n",
      "  [0.06339604 0.01759914 0.02181288 0.         0.03351411 0.\n",
      "   0.00526312 0.00964189 0.         0.00087711 0.         0.00306214\n",
      "   0.         0.         0.00378612 0.03538098 0.         0.\n",
      "   0.         0.         0.         0.         0.00350289 0.0315371\n",
      "   0.         0.         0.         0.         0.010626   0.07200741\n",
      "   0.03575949 0.        ]\n",
      "  [0.06339604 0.01759914 0.02181288 0.         0.03351411 0.\n",
      "   0.00526312 0.00964189 0.         0.00087711 0.         0.00306214\n",
      "   0.         0.         0.00378612 0.03538098 0.         0.\n",
      "   0.         0.         0.         0.         0.00350289 0.0315371\n",
      "   0.         0.         0.         0.         0.010626   0.07200741\n",
      "   0.03575949 0.        ]]]\n",
      "Max pool output: [[0.07870724 0.05547646 0.0684483  0.04562294 0.10473784 0.\n",
      "  0.07075743 0.03232131 0.02580475 0.00087711 0.         0.07566359\n",
      "  0.02025691 0.01473156 0.01074565 0.07701567 0.04481992 0.\n",
      "  0.         0.04659469 0.09731936 0.0394225  0.06145326 0.0315371\n",
      "  0.02405596 0.11169372 0.04307384 0.04142802 0.0526284  0.07200741\n",
      "  0.04061187 0.03251328]]\n"
     ]
    }
   ],
   "source": [
    "# the outputs of each layer\n",
    "print(f\"Embedding output: {embedding_test}\")\n",
    "print(f\"Conv1D output: {conv_1d_output}\")\n",
    "print(f\"Max pool output: {max_pool_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model using 1D CNN\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "\n",
    "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)  # Reduced kernel size\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\", name=\"ouput_layer\")(x)\n",
    "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 11, 32)            20512     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 32)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " ouput_layer (Dense)         (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,300,545\n",
      "Trainable params: 1,300,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_5_CNN/20241016-113203\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 5s 17ms/step - loss: 0.1328 - accuracy: 0.9620 - val_loss: 0.8630 - val_accuracy: 0.7677\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.0755 - accuracy: 0.9730 - val_loss: 1.0040 - val_accuracy: 0.7651\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.0606 - accuracy: 0.9762 - val_loss: 1.1032 - val_accuracy: 0.7625\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.0545 - accuracy: 0.9785 - val_loss: 1.1434 - val_accuracy: 0.7546\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.0492 - accuracy: 0.9793 - val_loss: 1.2041 - val_accuracy: 0.7572\n"
     ]
    }
   ],
   "source": [
    "# Compile the model_5\n",
    "model_5.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model_5\n",
    "model_5_history = model_5.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
    "                                                                     experiment_name=\"model_5_CNN\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((762, 1),\n",
       " array([[6.1308973e-02],\n",
       "        [7.0707142e-01],\n",
       "        [9.9990129e-01],\n",
       "        [3.9277494e-02],\n",
       "        [9.7136876e-07],\n",
       "        [9.9201107e-01],\n",
       "        [9.6536607e-01],\n",
       "        [9.9998063e-01],\n",
       "        [9.9999899e-01],\n",
       "        [8.3541203e-01]], dtype=float32))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make prediction with model_5\n",
    "model_5_pred_probs = model_5.predict(val_sentences)\n",
    "model_5_pred_probs.shape, model_5_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert pred probs to labels\n",
    "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
    "model_5_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 75.7217847769029,\n",
       " 'precision': 0.7574646046920478,\n",
       " 'recall': 0.7572178477690289,\n",
       " 'f1 score': 0.7557133417830909}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_5 results\n",
    "model_5_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_5_preds)\n",
    "\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6: TensorFlow Hub Pretrained Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There's a flood in the streets of New York\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "# embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "# embed_samples = embed([sample_sentence,\n",
    "#                        \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
    "# print(embed_samples[0][:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "# Create a Keras Layer using the USE pretrained layer from tensorflow hub\n",
    "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        input_shape=[],\n",
    "                                        dtype=tf.string,\n",
    "                                        trainable=False,\n",
    "                                        name=\"USE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ceate a model using the Sequential API\n",
    "from tensorflow.keras import layers\n",
    "model_6 = tf.keras.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\",\n",
    "                 name=\"output_layer\")\n",
    "], name=\"model_6_USE\")\n",
    "\n",
    "# Compile the model_6\n",
    "model_6.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Model_6 summary\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Ceate a model using the Sequential API\n",
    "from tensorflow.keras import layers\n",
    "model_6 = tf.keras.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\",\n",
    "                 name=\"output_layer\")\n",
    "], name=\"model_6_USE\")\n",
    "\n",
    "# Compile the model_6\n",
    "model_6.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Model_6 summary\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20241016-113232\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 7s 10ms/step - loss: 0.5056 - accuracy: 0.7808 - val_loss: 0.4549 - val_accuracy: 0.7992\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.4151 - accuracy: 0.8143 - val_loss: 0.4394 - val_accuracy: 0.8110\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.4008 - accuracy: 0.8224 - val_loss: 0.4352 - val_accuracy: 0.8071\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.3931 - accuracy: 0.8263 - val_loss: 0.4327 - val_accuracy: 0.8150\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.3852 - accuracy: 0.8313 - val_loss: 0.4277 - val_accuracy: 0.8136\n"
     ]
    }
   ],
   "source": [
    "# Fit the model_6\n",
    "model_6_history = model_6.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
    "                                                                     \"tf_hub_sentence_encoder\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.28891802],\n",
       "       [0.8570126 ],\n",
       "       [0.9975726 ],\n",
       "       [0.08191413],\n",
       "       [0.10381918],\n",
       "       [0.9258567 ],\n",
       "       [0.88871014],\n",
       "       [0.99258786],\n",
       "       [0.96224165],\n",
       "       [0.20009117]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with USE TF Hub Model\n",
    "model_6_pred_probs = model_6.predict(val_sentences)\n",
    "model_1_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert predicton probabilities to labels\n",
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "model_6_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.36482939632546,\n",
       " 'precision': 0.8137644815279499,\n",
       " 'recall': 0.8136482939632546,\n",
       " 'f1 score': 0.8130185559585642}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_6 results\n",
    "model_6_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_6_preds)\n",
    "\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Check for tensorflow gpu availability\n",
    "print(tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7: Same as model 6 with 10% of the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: Making data splits like below leads to data leakage (model_7 trained on 10% data, outperforms model_6 trained on 100% data)\n",
    "DO NOT MAKE DATA SPLITS WHICH LEAK DATA FROM VALIDATION/TEST SETS INTO TRAINING SET \n",
    "\n",
    "Create subsets of 10% of the training data\n",
    "train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
    "train_10_percent.head(), len(train_10_percent)\n",
    "train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
    "train_labels_10_percent = train_10_percent[\"target\"].to_list()\n",
    "len(train_sentences_10_percent), len(train_labels_10_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make 10% data split\n",
    "train_10_percent_split = int(0.1 * len(train_sentences))\n",
    "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
    "train_labels_10_percent = train_labels[:train_10_percent_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    406\n",
       "1    279\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of each label in the updated training data subset\n",
    "pd.Series(np.array(train_labels_10_percent)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4342\n",
       "1    3271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of targets in our subset of data\n",
    "train_df_shuffled[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                32832     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model_7 same as model_6\n",
    "model_7 = tf.keras.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")\n",
    "], name=\"model_7_USE\")\n",
    "\n",
    "# Compile the model_7\n",
    "model_7.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# Get a model_7 summery\n",
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/tf_hub_sentence_ecoder_10_percent_correct_spilt/20241016-113246\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 42ms/step - loss: 0.6734 - accuracy: 0.6482 - val_loss: 0.6468 - val_accuracy: 0.7520\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.6008 - accuracy: 0.8131 - val_loss: 0.5892 - val_accuracy: 0.7690\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.5244 - accuracy: 0.8175 - val_loss: 0.5331 - val_accuracy: 0.7861\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.4621 - accuracy: 0.8190 - val_loss: 0.5025 - val_accuracy: 0.7835\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.4201 - accuracy: 0.8321 - val_loss: 0.4887 - val_accuracy: 0.7861\n"
     ]
    }
   ],
   "source": [
    "# Fit the model_7 with 10% data split\n",
    "model_7_history = model_7.fit(train_sentences_10_percent,\n",
    "                              train_labels_10_percent,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels),\n",
    "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
    "\n",
    "                                                                     \"tf_hub_sentence_ecoder_10_percent_correct_spilt\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.1888037 ],\n",
       "       [0.5827515 ],\n",
       "       [0.92235136],\n",
       "       [0.38098192],\n",
       "       [0.5570362 ],\n",
       "       [0.6806969 ],\n",
       "       [0.8921712 ],\n",
       "       [0.78996825],\n",
       "       [0.84216595],\n",
       "       [0.12167007]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with the model_7\n",
    "model_7_pred_probs = model_7.predict(val_sentences)\n",
    "model_7_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert pred probs to labels\n",
    "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
    "\n",
    "model_7_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.60892388451444,\n",
       " 'precision': 0.7874601430270979,\n",
       " 'recall': 0.7860892388451444,\n",
       " 'f1 score': 0.7844405481342521}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_7 results\n",
    "model_7_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_7_preds)\n",
    "\n",
    "model_7_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the performance of each of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_baseline</th>\n",
       "      <td>79.265092</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_simple_dense</th>\n",
       "      <td>79.002625</td>\n",
       "      <td>0.798644</td>\n",
       "      <td>0.790026</td>\n",
       "      <td>0.785983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_lstm</th>\n",
       "      <td>77.034121</td>\n",
       "      <td>0.771825</td>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.768323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_gru</th>\n",
       "      <td>77.821522</td>\n",
       "      <td>0.781072</td>\n",
       "      <td>0.778215</td>\n",
       "      <td>0.775746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_bidirectional</th>\n",
       "      <td>76.377953</td>\n",
       "      <td>0.763805</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.762589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_conv1d</th>\n",
       "      <td>75.721785</td>\n",
       "      <td>0.757465</td>\n",
       "      <td>0.757218</td>\n",
       "      <td>0.755713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_tf_hub_use_encoder</th>\n",
       "      <td>81.364829</td>\n",
       "      <td>0.813764</td>\n",
       "      <td>0.813648</td>\n",
       "      <td>0.813019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_tf_hub_use_encoder_10_percent</th>\n",
       "      <td>78.608924</td>\n",
       "      <td>0.787460</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.784441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  accuracy  precision    recall  f1 score\n",
       "0_baseline                       79.265092   0.811139  0.792651  0.786219\n",
       "1_simple_dense                   79.002625   0.798644  0.790026  0.785983\n",
       "2_lstm                           77.034121   0.771825  0.770341  0.768323\n",
       "3_gru                            77.821522   0.781072  0.778215  0.775746\n",
       "4_bidirectional                  76.377953   0.763805  0.763780  0.762589\n",
       "5_conv1d                         75.721785   0.757465  0.757218  0.755713\n",
       "6_tf_hub_use_encoder             81.364829   0.813764  0.813648  0.813019\n",
       "7_tf_hub_use_encoder_10_percent  78.608924   0.787460  0.786089  0.784441"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine model results into a DataFrame\n",
    "all_model_results = pd.DataFrame({\"0_baseline\": baseline_results,\n",
    "                                  \"1_simple_dense\": model_1_results,\n",
    "                                  \"2_lstm\": model_2_results,\n",
    "                                  \"3_gru\": model_3_results,\n",
    "                                  \"4_bidirectional\": model_4_results,\n",
    "                                  \"5_conv1d\": model_5_results,\n",
    "                                  \"6_tf_hub_use_encoder\": model_6_results,\n",
    "                                  \"7_tf_hub_use_encoder_10_percent\": model_7_results})\n",
    "all_model_results = all_model_results.transpose()\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_baseline</th>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_simple_dense</th>\n",
       "      <td>0.790026</td>\n",
       "      <td>0.798644</td>\n",
       "      <td>0.790026</td>\n",
       "      <td>0.785983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_lstm</th>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.771825</td>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.768323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_gru</th>\n",
       "      <td>0.778215</td>\n",
       "      <td>0.781072</td>\n",
       "      <td>0.778215</td>\n",
       "      <td>0.775746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_bidirectional</th>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.763805</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.762589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_conv1d</th>\n",
       "      <td>0.757218</td>\n",
       "      <td>0.757465</td>\n",
       "      <td>0.757218</td>\n",
       "      <td>0.755713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_tf_hub_use_encoder</th>\n",
       "      <td>0.813648</td>\n",
       "      <td>0.813764</td>\n",
       "      <td>0.813648</td>\n",
       "      <td>0.813019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_tf_hub_use_encoder_10_percent</th>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.787460</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.784441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 accuracy  precision    recall  f1 score\n",
       "0_baseline                       0.792651   0.811139  0.792651  0.786219\n",
       "1_simple_dense                   0.790026   0.798644  0.790026  0.785983\n",
       "2_lstm                           0.770341   0.771825  0.770341  0.768323\n",
       "3_gru                            0.778215   0.781072  0.778215  0.775746\n",
       "4_bidirectional                  0.763780   0.763805  0.763780  0.762589\n",
       "5_conv1d                         0.757218   0.757465  0.757218  0.755713\n",
       "6_tf_hub_use_encoder             0.813648   0.813764  0.813648  0.813019\n",
       "7_tf_hub_use_encoder_10_percent  0.786089   0.787460  0.786089  0.784441"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the accuracy to same scale as other metrics\n",
    "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and compare all of the model results\n",
    "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Slot model results by f1-score\n",
    "all_model_results.sort_values(\"f1 score\", ascending=False)[\"f1 score\"].plot(kind=\"bar\", figsize=(10, 7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

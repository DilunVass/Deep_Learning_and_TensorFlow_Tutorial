{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone Project 2\n",
    "\n",
    "### Problem Statement\n",
    "The number of RCT papers released is continuously increasing. It is difficult for researchers to keep up with the latest research in their field. This project aims to create a tool that can help researchers to keep up with the latest research in their field. The tool will be able to search for the latest RCT papers in a specific field and summarize the key findings of the papers.\n",
    "\n",
    "### Solution\n",
    "Create an NLP model to classify abstract sentences into the role they play (e.g. objective, methods, results, etc)  to enable researchers to skim through the literature (hence SkimLit ðŸ¤“ðŸ”¥) and dive deeper when necessary.\n",
    "\n",
    "> ðŸ“– **Resources:** Before going through the code in this notebook, you might want to get a background of what we're going to be doing. To do so, spend an hour (or two) going through the following papers and then return to this notebook:\n",
    "1. Where our data is coming from: [*PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts*](https://arxiv.org/abs/1710.06071)\n",
    "2. Where our model is coming from: [*Neural networks for joint sentence\n",
    "classification in medical paper abstracts*](https://arxiv.org/pdf/1612.05251.pdf).\n",
    "\n",
    "## Topics to be covered\n",
    "* Downloading a dataset ([PubMed RCT200k from GitHub](https://github.com/Franck-Dernoncourt/pubmed-rct))\n",
    "* Preprocessing data for NLP models\n",
    "* Setting up a series of NLP models\n",
    "    * Making a baseline model (TF-IDF Multinomial Naive Bayes)\n",
    "    * Deep models with different combinations of layers (Conv1D, LSTM, GRU)\n",
    "* Building first multimodal model (feature extraction and token embeddings)\n",
    "    * Replicating the model architecture from https://arxiv.org/abs/1612.05251\n",
    "* Find the most wrong predictions\n",
    "* Making predictions on PubMed abstracts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data\n",
    "\n",
    "* `train.txt` - training samples\n",
    "* `dev.txt` - validation samples\n",
    "* `test.txt` - test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strat by using the 20k dataset\n",
    "data_dir = \"data/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
       " 'data/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
       " 'data/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check all of the filenames in the data directory\n",
    "import os\n",
    "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to read the lines of the documents\n",
    "def get_lines(filename):\n",
    "    \"\"\"\n",
    "    Reads filename (a text filename) and returns the lines of text as a list.\n",
    "    Args:\n",
    "    filename: a string containing the target text filename.\n",
    "    Returns:\n",
    "    A list of strings with one string per line from the target text filename.\n",
    "    \"\"\"\n",
    "    with open(filename, \"r\") as file:\n",
    "        return file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['###24293578\\n',\n",
       " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
       " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
       " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
       " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
       " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
       " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
       " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
       " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
       " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
       " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
       " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
       " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
       " '\\n',\n",
       " '###24854809\\n',\n",
       " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
       " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
       " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
       " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
       " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lines = get_lines(data_dir + \"train.txt\")\n",
    "train_lines[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to read the lines of the documents\n",
    "def preprocess_text_with_line_numbers(filename):\n",
    "    \"\"\"\n",
    "    Returns a list of dictionaries of abstract line data.\n",
    "    \n",
    "    Takes in filename, reads its contents and sorts through each line,\n",
    "    extracting things like the line number, the text of the sentence,\n",
    "    and the target label.\n",
    "\n",
    "    Args:\n",
    "    filename: a string containing the target text filename.\n",
    "\n",
    "    Returns:\n",
    "    A list of dictionaries each containing the key value pairs for\n",
    "    line_number, target, and text.\n",
    "    \"\"\"\n",
    "\n",
    "    input_lines = get_lines(filename) # get all lines from filename\n",
    "    abstract_lines = \"\" # create an empty abstract\n",
    "    abstract_samples = [] # create an empty list to hold abstracts\n",
    "\n",
    "    # Loop through each line in the target file\n",
    "    for line in input_lines:\n",
    "        if line.startswith(\"###\"): # check to see if line is an ID line\n",
    "            abstract_id = line\n",
    "            abstract_lines = \"\" # reset abstract string\n",
    "        elif line.isspace(): # check to see if line is a new line\n",
    "            abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines\n",
    "\n",
    "            # Iterate through each line in abstract and count them at the same time\n",
    "            for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
    "                line_data = {} # create an empty dictionary for each line\n",
    "                target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
    "                line_data[\"target\"] = target_text_split[0] # get target label\n",
    "                line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
    "                line_data[\"line_number\"] = abstract_line_number # what line number does the line appear in the abstract?\n",
    "                line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are in the abstarct? (start from 0)\n",
    "                abstract_samples.append(line_data) # add line data to absract samples list\n",
    "\n",
    "            else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
    "                abstract_lines += line\n",
    "\n",
    "            return abstract_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
